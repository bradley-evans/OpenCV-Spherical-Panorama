{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import imutils\n",
        "import cv2\n",
        "import argparse\n",
        "\n",
        "# stuff just for IPython\n",
        "from IPython.display import display\n",
        "from IPython.display import Image\n",
        "from matplotlib import pyplot as plt"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false,
        "outputExpanded": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stitcher class\n",
        "\nThis is a class provided by OpenCV that achieves basic left-to-right stitching."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class Stitcher:\n",
        "\tdef __init__(self):\n",
        "\t\t# determine if we are using OpenCV v3.X\n",
        "\t\tself.isv3 = imutils.is_cv3()\n",
        "\n",
        "\tdef stitch(self, images, ratio=0.75, reprojThresh=4.0,\n",
        "\t\tshowMatches=False):\n",
        "\t\t# unpack the images, then detect keypoints and extract\n",
        "\t\t# local invariant descriptors from them\n",
        "\t\t(imageB, imageA) = images\n",
        "\t\t(kpsA, featuresA) = self.detectAndDescribe(imageA)\n",
        "\t\t(kpsB, featuresB) = self.detectAndDescribe(imageB)\n",
        "\n",
        "\t\t# match features between the two images\n",
        "\t\tM = self.matchKeypoints(kpsA, kpsB,\n",
        "\t\t\tfeaturesA, featuresB, ratio, reprojThresh)\n",
        "\n",
        "\t\t# if the match is None, then there aren't enough matched\n",
        "\t\t# keypoints to create a panorama\n",
        "\t\tif M is None:\n",
        "\t\t\treturn None\n",
        "\n",
        "\t\t# otherwise, apply a perspective warp to stitch the images\n",
        "\t\t# together\n",
        "\t\t(matches, H, status) = M\n",
        "\t\tresult = cv2.warpPerspective(imageA, H,\n",
        "\t\t\t(imageA.shape[1] + imageB.shape[1], imageA.shape[0]))\n",
        "\t\tresult[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n",
        "\n",
        "\t\t# check to see if the keypoint matches should be visualized\n",
        "\t\tif showMatches:\n",
        "\t\t\tvis = self.drawMatches(imageA, imageB, kpsA, kpsB, matches,\n",
        "\t\t\t\tstatus)\n",
        "\n",
        "\t\t\t# return a tuple of the stitched image and the\n",
        "\t\t\t# visualization\n",
        "\t\t\treturn (result, vis)\n",
        "\n",
        "\t\t# return the stitched image\n",
        "\t\treturn result\n",
        "\n",
        "\tdef detectAndDescribe(self, image):\n",
        "\t\t# convert the image to grayscale\n",
        "\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\t\t# check to see if we are using OpenCV 3.X\n",
        "\t\tif self.isv3:\n",
        "\t\t\t# detect and extract features from the image\n",
        "\t\t\tdescriptor = cv2.xfeatures2d.SIFT_create()\n",
        "\t\t\t(kps, features) = descriptor.detectAndCompute(image, None)\n",
        "\n",
        "\t\t# otherwise, we are using OpenCV 2.4.X\n",
        "\t\telse:\n",
        "\t\t\t# detect keypoints in the image\n",
        "\t\t\tdetector = cv2.FeatureDetector_create(\"SIFT\")\n",
        "\t\t\tkps = detector.detect(gray)\n",
        "\n",
        "\t\t\t# extract features from the image\n",
        "\t\t\textractor = cv2.DescriptorExtractor_create(\"SIFT\")\n",
        "\t\t\t(kps, features) = extractor.compute(gray, kps)\n",
        "\n",
        "\t\t# convert the keypoints from KeyPoint objects to NumPy\n",
        "\t\t# arrays\n",
        "\t\tkps = np.float32([kp.pt for kp in kps])\n",
        "\n",
        "\t\t# return a tuple of keypoints and features\n",
        "\t\treturn (kps, features)\n",
        "\n",
        "\tdef matchKeypoints(self, kpsA, kpsB, featuresA, featuresB,\n",
        "\t\tratio, reprojThresh):\n",
        "\t\t# compute the raw matches and initialize the list of actual\n",
        "\t\t# matches\n",
        "\t\tmatcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
        "\t\trawMatches = matcher.knnMatch(featuresA, featuresB, 2)\n",
        "\t\tmatches = []\n",
        "\n",
        "\t\t# loop over the raw matches\n",
        "\t\tfor m in rawMatches:\n",
        "\t\t\t# ensure the distance is within a certain ratio of each\n",
        "\t\t\t# other (i.e. Lowe's ratio test)\n",
        "\t\t\tif len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
        "\t\t\t\tmatches.append((m[0].trainIdx, m[0].queryIdx))\n",
        "\n",
        "\t\t# computing a homography requires at least 4 matches\n",
        "\t\tif len(matches) > 4:\n",
        "\t\t\t# construct the two sets of points\n",
        "\t\t\tptsA = np.float32([kpsA[i] for (_, i) in matches])\n",
        "\t\t\tptsB = np.float32([kpsB[i] for (i, _) in matches])\n",
        "\n",
        "\t\t\t# compute the homography between the two sets of points\n",
        "\t\t\t(H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC,\n",
        "\t\t\t\treprojThresh)\n",
        "\n",
        "\t\t\t# return the matches along with the homograpy matrix\n",
        "\t\t\t# and status of each matched point\n",
        "\t\t\treturn (matches, H, status)\n",
        "\n",
        "\t\t# otherwise, no homograpy could be computed\n",
        "\t\treturn None\n",
        "\n",
        "\tdef drawMatches(self, imageA, imageB, kpsA, kpsB, matches, status):\n",
        "\t\t# initialize the output visualization image\n",
        "\t\t(hA, wA) = imageA.shape[:2]\n",
        "\t\t(hB, wB) = imageB.shape[:2]\n",
        "\t\tvis = np.zeros((max(hA, hB), wA + wB, 3), dtype=\"uint8\")\n",
        "\t\tvis[0:hA, 0:wA] = imageA\n",
        "\t\tvis[0:hB, wA:] = imageB\n",
        "\n",
        "\t\t# loop over the matches\n",
        "\t\tfor ((trainIdx, queryIdx), s) in zip(matches, status):\n",
        "\t\t\t# only process the match if the keypoint was successfully\n",
        "\t\t\t# matched\n",
        "\t\t\tif s == 1:\n",
        "\t\t\t\t# draw the match\n",
        "\t\t\t\tptA = (int(kpsA[queryIdx][0]), int(kpsA[queryIdx][1]))\n",
        "\t\t\t\tptB = (int(kpsB[trainIdx][0]) + wA, int(kpsB[trainIdx][1]))\n",
        "\t\t\t\tcv2.line(vis, ptA, ptB, (0, 255, 0), 1)\n",
        "\n",
        "\t\t# return the visualization\n",
        "\t\treturn vis"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false,
        "outputExpanded": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test sequence 1: load images #\n",
        "imageA = cv2.imread('pano1_0008.jpg')\n",
        "imageB = cv2.imread('pano1_0009.jpg')\n",
        "imageC = cv2.imread('pano1_0010.jpg')\n",
        "imageD = cv2.imread('pano1_0011.jpg')\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imageA)\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(imageB)\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(imageC)\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(imageD)\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Image data cannot be converted to float",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-12-2960256d18d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python36\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3099\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3100\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3101\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3102\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3103\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python36\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1717\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python36\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5129\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5131\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5132\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python36\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    616\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    617\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 618\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         if not (self._A.ndim == 2\n",
            "\u001b[1;31mTypeError\u001b[0m: Image data cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x11ed50d3a58>"
            ],
            "image/png": [
              "iVBORw0KGgoAAAANSUhEUgAAAHUAAABsCAYAAABU3f3vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABNFJREFUeJztnEFoHGUYhp/X1irkYMH2IFqoxWLIwUO6SE4iiNDmkBz0kF5qpLIULZ4FD0Iv0pNQFEvEoPVQiz1FUARR6Km1G9CaKkoqiMFAU5VchGrg8zBDTNdNZnbzz+748T2wsDP/PzMf+zCb2Y/8r8yMwBd3DbqAID0h1SEh1SEh1SEh1SEh1SGFUiXNSropaWGTcUk6I2lR0jVJo+nLDLqhzJ36HnB4i/EjwMH81QTe3n5ZwXYolGpml4Dft5gyCZyzjMvAbkkPpCow6J4Uf1MfBH7ZsL2U7wsGxM4E51CHfR17j5KaZF/RDA0NHRoeHk5web/Mz8/fMrO93R6XQuoSsG/D9kPAr50mmtkMMAPQaDSs1WoluLxfJP3cy3Epvn7ngGP5U/AYsGpmywnOG/RI4Z0q6TzwJLBH0hLwGnA3gJmdBT4BxoFF4E/g+aqKDcpRKNXMjhaMG/BSsoqCbRMdJYeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeEVIeUkirpsKQf8rCOVzqMT0takfR1/nohfalBWcosZdwBvAU8TbbA+KqkOTP7rm3qBTM7WUGNQZeUuVMfBxbN7Ccz+wv4kCy8I6gpZaSWDep4Js9RuihpX4dxJDUltSS1VlZWeig3KEMZqWWCOj4G9pvZY8DnwPudTmRmM2bWMLPG3r1d51MEJSkjtTCow8x+M7Pb+eY7wKE05QW9UEbqVeCgpIcl7QKmyMI71mkLw5oAvk9XYtAtZTIf1iSdBD4DdgCzZnZd0imgZWZzwMuSJoA1snS06QprDgrQoDL0I0epGEnzZtbo9rjoKDkkpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokpDokVebDPZIu5ONXJO1PXWhQnkKpGzIfjgAjwFFJI23TjgN/mNkjwBvA6dSFBuVJlfkwyb+rxy8CT0nqtAI96AOpMh/W55jZGrAK3J+iwKB7ChcdUy7zocwcJDWBZr55W9JCiev3iz3ArUEX0cajvRxURmph5sOGOUuSdgL3ka0ovwMzmwFmACS1ellQWxV1qweymno5LknmQ779XP7+WeALG9QS9SBZ5sO7wAeSFsnu0Kkqiw62ZmCZD5Ka+ddxLahbPdB7TQOTGlRHtAkdUrnUurUY6xZzK2lW0s3Nft4p40xe7zVJo4UnNbPKXmQPVjeAA8Au4BtgpG3Oi8DZ/P0UWcTsIOuZBt6s8nNpu94TwCiwsMn4OPApWS9gDLhSdM6q79S6tRhrF3NrZpfo8Jt+A5PAOcu4DOxuiw38D1VLrVuLMVnMbR8pW/M6VUtN1mJMRLKY2z7S9edTtdRuWoxs1WLsVz01jLkt8xneQdVS69Zi/D/G3M4Bx/Kn4DFg1cyWtzyiD09348CPZE+dr+b7TgET+ft7gY+AReAr4MCA63kduE72ZPwlMFxxPeeBZeBvsrvyOHACOJGPi+yfFG4A3wKNonNGR8kh0VFySEh1SEh1SEh1SEh1SEh1SEh1SEh1yD9fDJ3/fOU3QgAAAABJRU5ErkJggg==\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false,
        "outputExpanded": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test sequence 2: run stitcher on two images #\n",
        "\n",
        "stitcher = Stitcher()\n",
        "(result,vis) = stitcher.stitch([imageB,imageA],showMatches = True)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(vis)\n",
        "plt.title(\"Keypoint Matches\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(result)\n",
        "plt.title(\"Result\")\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:11111: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-fa04dffdf00c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstitcher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStitcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstitcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimageB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimageA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshowMatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-11-454d0c9f6681>\u001b[0m in \u001b[0;36mstitch\u001b[1;34m(self, images, ratio, reprojThresh, showMatches)\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[1;31m# local invariant descriptors from them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mimageB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mkpsA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndDescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mkpsB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesB\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndDescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-11-454d0c9f6681>\u001b[0m in \u001b[0;36mdetectAndDescribe\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdetectAndDescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[1;31m# convert the image to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;31m# check to see if we are using OpenCV 3.X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:11111: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false,
        "outputExpanded": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note that the order does appear to matter.\n",
        "# trying to reverse the order of the inputs into the stitcher\n",
        "# gets you something like this\n",
        "\n",
        "(result,vis) = stitcher.stitch([imageA,imageB],showMatches = True)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(vis)\n",
        "plt.title(\"Keypoint Matches\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(result)\n",
        "plt.title(\"Result\")\n",
        "plt.show()\n",
        "# Note that the result obtained is not a stitched image.\n",
        "\n",
        "# this is just to put things back as they were after the demonstration\n",
        "(result,vis) = stitcher.stitch([imageB,imageA],showMatches = True)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:11111: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-14-d28efeddc0f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# gets you something like this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstitcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimageA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimageB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshowMatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-11-454d0c9f6681>\u001b[0m in \u001b[0;36mstitch\u001b[1;34m(self, images, ratio, reprojThresh, showMatches)\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[1;31m# local invariant descriptors from them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mimageB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mkpsA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndDescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mkpsB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesB\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndDescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-11-454d0c9f6681>\u001b[0m in \u001b[0;36mdetectAndDescribe\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdetectAndDescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[1;31m# convert the image to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;31m# check to see if we are using OpenCV 3.X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:11111: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false,
        "outputExpanded": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we need to start stitching multiple images together\n",
        "current_pano = result\n",
        "(result,vis) = stitcher.stitch([imageC,current_pano],showMatches = True)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(vis)\n",
        "plt.title(\"Keypoint Matches\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(result)\n",
        "plt.title(\"Result\")\n",
        "plt.show()\n",
        "\n",
        "current_pano = result\n",
        "(result,vis) = stitcher.stitch([imageD,current_pano],showMatches = True)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(vis)\n",
        "plt.title(\"Keypoint Matches\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(result)\n",
        "plt.title(\"Result\")\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-27ea527d87c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# now we need to start stitching multiple images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcurrent_pano\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstitcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimageC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrent_pano\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshowMatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false,
        "outputExpanded": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attempting to Stitch Horizontally and Vertically.\n",
        "\n",
        "Now that we more or less understand horizontal stitching, we need a method of doing this in x and y. I generated the following dataset to test methods.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import helperfuncs\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "# This will display all of the images we're going to use\n",
        "# for this experiment in order. \n",
        "i = 1\n",
        "for x in range(0,11):\n",
        "    for y in range (0,3):\n",
        "        filename = helperfuncs.getFilename(x,y)\n",
        "        img = cv2.imread(filename)\n",
        "        plt.subplot(3,11,i)\n",
        "        plt.imshow(img)\n",
        "        i = i+1\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'helperfuncs'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-e9cde4e8ba8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhelperfuncs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# This will display all of the images we're going to use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helperfuncs'"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import rotate\n",
        "import helperfuncs\n",
        "import cv2\n",
        "\n",
        "# Now let's go ahead and perform stitching. First, we'll\n",
        "# stitch images vertically by rotating them and stitching\n",
        "# them using the horizontal left-right method.\n",
        "\n",
        "# First, experiment with performing the procedure manually.\n",
        "img0 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(0,0)),(0,0),fx=0.4,fy=0.4),270)\n",
        "img1 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(0,1)),(0,0),fx=0.4,fy=0.4),270)\n",
        "img2 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(0,2)),(0,0),fx=0.4,fy=0.4),270)\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img0)\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(img1)\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(img2)\n",
        "plt.show()\n",
        "result1 = stitcher.stitch([img2,img1],showMatches = False)\n",
        "result = stitcher.stitch([result1,img0],showMatches = False)\n",
        "resultA = rotate(result,90)\n",
        "plt.imshow(resultA)\n",
        "\n",
        "img0 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(1,0)),(0,0),fx=0.4,fy=0.4),270)\n",
        "img1 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(1,1)),(0,0),fx=0.4,fy=0.4),270)\n",
        "img2 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(1,2)),(0,0),fx=0.4,fy=0.4),270)\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img0)\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(img1)\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(img2)\n",
        "plt.show()\n",
        "result1 = stitcher.stitch([img2,img1],showMatches = False)\n",
        "result = stitcher.stitch([result1,img0],showMatches = False)\n",
        "resultB = rotate(result,90)\n",
        "plt.imshow(resultB)\n",
        "\n",
        "result_final = stitcher.stitch([resultA,resultB],showMatches = False)\n",
        "plt.imshow(result_final)\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'helperfuncs'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-17-c8b530de7541>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrotate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhelperfuncs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Now let's go ahead and perform stitching. First, we'll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helperfuncs'"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import rotate\n",
        "import helperfuncs\n",
        "import cv2\n",
        "\n",
        "# The test above was marginally successful. Let's attempt to loop through.\n",
        "\n",
        "for x in range(0,11):\n",
        "    print('Current Iteration: ' + str(x))\n",
        "    if x==0:\n",
        "        img0 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(0,0)),(0,0),fx=0.4,fy=0.4),270)\n",
        "        img1 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(0,1)),(0,0),fx=0.4,fy=0.4),270)\n",
        "        img2 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(0,2)),(0,0),fx=0.4,fy=0.4),270)\n",
        "        result1 = stitcher.stitch([img2,img1],showMatches = False)\n",
        "        result = stitcher.stitch([result1,img0],showMatches = False)\n",
        "        prevResult = rotate(result,90)\n",
        "    else:\n",
        "        img0 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(x,0)),fx=0.4,fy=0.4),270)\n",
        "        img1 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(x,1)),fx=0.4,fy=0.4),270)\n",
        "        img2 = rotate(cv2.resize(cv2.imread(helperfuncs.getFilename(x,2)),fx=0.4,fy=0.4),270)\n",
        "        result1 = stitcher.stitch([img2,img1],showMatches = False)\n",
        "        result = stitcher.stitch([result1,img0],showMatches = False)\n",
        "        result = rotate(result,90)\n",
        "        finalresult = stitcher.stitch([prevResult,result],showMatches = False)\n",
        "        prevResult = finalresult\n",
        "        plt.imshow(finalresult)\n",
        "        plt.show()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'helperfuncs'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-18-40b0ad65b13e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrotate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhelperfuncs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# The test above was marginally successful. Let's attempt to loop through.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helperfuncs'"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.7.1"
    },
    "gist_id": "6c9d2d136e1975f39e73f6504aa9a966"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}